scalib(pred_risk = predrisk,
pred_horizon = pred_horizon,
event_status = data_test$death,
event_time = data_test$futime)
.scalib
# Chunk 9
# keeping max dimension low to reduce computation time
.scalib_slope <- scalib_hare(scalib_object = .scalib)
# scalib_hare modifies the scalib object by adding output data
.scalib_slope
# Chunk 10
gg_data <- .scalib_slope %>%
getElement("data_outputs") %>%
select(._id_., hare_data_plot) %>%
unnest(hare_data_plot)
fig_cal_slope <- ggplot(gg_data) +
aes(x = predicted, y = observed) +
geom_line() +
geom_abline(col = 'grey', linetype = 2, intercept = 0, slope = 1) +
scale_x_continuous(limits = c(0,1),
expand = c(0,0),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%")) +
scale_y_continuous(limits = c(-0, 1),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%"))
fig_cal_slope
# Chunk 11
data_segment <- predrisk_bin_segments(.scalib_slope,
bin_count = 100,
bin_yintercept = 0,
bin_length = 1)
head(data_segment)
# Chunk 12
fig_cal_slope_hist <- fig_cal_slope +
geom_segment(data = data_segment,
inherit.aes = FALSE,
size = 1.2,
color = 'grey',
mapping = aes(x = x,
y = y,
xend = xend,
yend = yend))
fig_cal_slope_hist
# Chunk 13
.scalib_smry <- .scalib_slope %>%
getElement("data_outputs") %>%
select(hare_ici, hare_e50, hare_e90, hare_emax)
# Chunk 14
rspec <- round_spec() %>%
round_half_even() %>%
round_using_decimal(digits = 3)
annotate_label <- table_glue(
'Integrated calibration index: {.scalib_smry$hare_ici}
E50: {.scalib_smry$hare_e50}
E90: {.scalib_smry$hare_e90}
Emax: {.scalib_smry$hare_emax}',
rspec = rspec
)
fig_cal_slope_hist_annotate <-
fig_cal_slope_hist +
annotate(
geom = 'text',
x = 0.05,
y = 0.80,
hjust = 0,
label = annotate_label
)
fig_cal_slope_hist_annotate
.scalib_test <- scalib_gnd(scalib_object = .scalib,
group_count_init = 7)
library(survival.calib)
# Chunk 1
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# Chunk 2: setup
library(survival.calib)
library(survival)
library(riskRegression)
library(dplyr)
library(tidyr)
library(ggplot2)
library(table.glue)
theme_set(theme_bw() + theme(panel.grid = element_blank()))
knitr::opts_chunk$set(fig.width=7, fig.height=5)
# Chunk 3
# drop rows with missing values for simplicity
data_init <- na.omit(flchain)
# Chunk 4
# sometimes chapter makes split-sample tests tricky
data_init$chapter <- NULL
# Chunk 5
head(data_init)
# Chunk 6
n_obs_total <- nrow(data_init)
n_obs_train <- round(n_obs_total * 2/3)
set.seed(705)
train_index <- sample(n_obs_total, size = n_obs_train)
data_train <- data_init[train_index, ]
data_test <- data_init[-train_index, ]
# Chunk 7
model <- coxph(Surv(futime, death) ~ .,
data = data_train,
x = TRUE)
# compute predicted risk at 1500 days post baseline
pred_horizon <- 1500
predrisk <- predictRisk(model,
newdata = data_test,
times = pred_horizon)
# tracemem(predrisk)
tracemem(data_test$death)
# Chunk 8
.scalib <-
scalib(pred_risk = predrisk,
pred_horizon = pred_horizon,
event_status = data_test$death,
event_time = data_test$futime)
.scalib
# Chunk 9
# keeping max dimension low to reduce computation time
.scalib_slope <- scalib_hare(scalib_object = .scalib)
# scalib_hare modifies the scalib object by adding output data
.scalib_slope
# Chunk 10
gg_data <- .scalib_slope %>%
getElement("data_outputs") %>%
select(._id_., hare_data_plot) %>%
unnest(hare_data_plot)
fig_cal_slope <- ggplot(gg_data) +
aes(x = predicted, y = observed) +
geom_line() +
geom_abline(col = 'grey', linetype = 2, intercept = 0, slope = 1) +
scale_x_continuous(limits = c(0,1),
expand = c(0,0),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%")) +
scale_y_continuous(limits = c(-0, 1),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%"))
fig_cal_slope
# Chunk 11
data_segment <- predrisk_bin_segments(.scalib_slope,
bin_count = 100,
bin_yintercept = 0,
bin_length = 1)
head(data_segment)
# Chunk 12
fig_cal_slope_hist <- fig_cal_slope +
geom_segment(data = data_segment,
inherit.aes = FALSE,
size = 1.2,
color = 'grey',
mapping = aes(x = x,
y = y,
xend = xend,
yend = yend))
fig_cal_slope_hist
# Chunk 13
.scalib_smry <- .scalib_slope %>%
getElement("data_outputs") %>%
select(hare_ici, hare_e50, hare_e90, hare_emax)
# Chunk 14
rspec <- round_spec() %>%
round_half_even() %>%
round_using_decimal(digits = 3)
annotate_label <- table_glue(
'Integrated calibration index: {.scalib_smry$hare_ici}
E50: {.scalib_smry$hare_e50}
E90: {.scalib_smry$hare_e90}
Emax: {.scalib_smry$hare_emax}',
rspec = rspec
)
fig_cal_slope_hist_annotate <-
fig_cal_slope_hist +
annotate(
geom = 'text',
x = 0.05,
y = 0.80,
hjust = 0,
label = annotate_label
)
fig_cal_slope_hist_annotate
.scalib_test <- scalib_gnd(scalib_object = .scalib,
group_count_init = 7)
# observed event status and times
# copy needed to avoid modifying input data
dt <- copy(scalib_object$data_inputs)
tracemem(dt)
dt
# curtailed events and times at prediction horizon
dt <- dt[
event_time > pred_horizon,
`:=`(
event_status = 0,
event_time = pred_horizon
)
]
dt <- melt(dt,
id.vars = c('event_status', 'event_time'),
measure.vars = pred_risk_cols,
variable.name = '._id_.')
n_pred_uni <- dt[, .(count=length(unique(value))), by = ._id_.]
if(any(n_pred_uni$count < group_count_init)){
offenders <- n_pred_uni[count < group_count_init, ._id_., drop = TRUE]
stop("The number of unique predicted risk values ",
"should be > the number of groups.\nSee input column(s) ",
paste_collapse(offenders, sep = ', ', last = 'and'),
call. = FALSE)
}
# create rankings of variable values (used to make percentile groups)
dt <- dt[, rank := frank(value), by = ._id_.]
# create the initial groups
dt <- dt[, group := ceiling((group_count_init)*rank/(.N+1)), by = ._id_.]
if(verbose > 0)
message("Checking event counts using ",
group_count_init, " risk groups...",
appendLF = FALSE)
# count the number of events in each group for each ._id_.
events <- dt[event_status == 1, .N, keyby = .(._id_., group)]
group_count <- group_count_init
ids_to_update <-
events[, .(.update = any(N < group_min_events)), by = ._id_.]
ids_to_update <-
ids_to_update[.update == TRUE, ._id_., drop = TRUE]
ids_to_update
is_empty(ids_to_update)
dt
dt_hoslem <- dt[
, .(
group_n = .N,
# count the number of events in each group
events_observed = sum(event_status),
events_expected = sum(value)
),
keyby = .(._id_., group)
]
dt_hoslem <- dt_hoslem[, percent_expected := events_expected / group_n]
dt_gnd <- dt[
,
# summarizing the inputs by fitting a survfit
# object to each group. Notably, we only need
# two things (surv and std.err) from the survfit
# object and they only need to be indexed at
# their second to last value. Need to unclass()
# survfit objects before pulling the data out.
lapply(
unclass(
survival::survfit(
formula = survival::Surv(event_time, event_status) ~ 1,
se.fit = TRUE
)
)[c('surv', 'std.err')],
function(x) x[length(x)-1]
),
keyby = .(._id_., group)
]
dt_gnd <- dt_gnd[, std.err := std.err * surv]
dt_gnd <- dt_gnd[dt_hoslem]
dt_gnd <- dt_gnd[
# mutate; derive some columns
, `:=`(
percent_observed = 1 - surv,
variance = std.err^2
)
][ # mutate again, using the columns we just made
, gnd_component := fifelse(
variance == 0,
yes = 0,
no = (percent_observed - percent_expected)^2 / variance
)
]
dt_gnd <- dt_gnd[
,
.(
gnd_df = .N - 1,
gnd_chisq = sum(gnd_component),
gnd_data = list(
data.table(
group,
group_n,
events_observed,
events_expected,
percent_observed,
percent_expected,
variance,
gnd_component)
),
gnd_group_method = group_method
),
by = ._id_.]
dt_gnd <- dt_gnd[, gnd_pvalue := 1 - stats::pchisq(gnd_chisq, gnd_df)]
dt_gnd <- dt_gnd[, .(._id_.,
gnd_df,
gnd_chisq,
gnd_pvalue,
gnd_data,
gnd_group_method) ]
scalib_absorb(scalib_object, dt_gnd)
# Chunk 1
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# Chunk 2: setup
library(survival.calib)
library(survival)
library(riskRegression)
library(dplyr)
library(tidyr)
library(ggplot2)
library(table.glue)
theme_set(theme_bw() + theme(panel.grid = element_blank()))
knitr::opts_chunk$set(fig.width=7, fig.height=5)
# Chunk 3
# drop rows with missing values for simplicity
data_init <- na.omit(flchain)
# Chunk 4
# sometimes chapter makes split-sample tests tricky
data_init$chapter <- NULL
# Chunk 5
head(data_init)
# Chunk 6
n_obs_total <- nrow(data_init)
n_obs_train <- round(n_obs_total * 2/3)
set.seed(705)
train_index <- sample(n_obs_total, size = n_obs_train)
data_train <- data_init[train_index, ]
data_test <- data_init[-train_index, ]
# Chunk 7
model <- coxph(Surv(futime, death) ~ .,
data = data_train,
x = TRUE)
# compute predicted risk at 1500 days post baseline
pred_horizon <- 1500
predrisk <- predictRisk(model,
newdata = data_test,
times = pred_horizon)
# tracemem(predrisk)
tracemem(data_test$death)
# Chunk 8
.scalib <-
scalib(pred_risk = predrisk,
pred_horizon = pred_horizon,
event_status = data_test$death,
event_time = data_test$futime)
.scalib
# Chunk 9
# keeping max dimension low to reduce computation time
.scalib_slope <- scalib_hare(scalib_object = .scalib)
# scalib_hare modifies the scalib object by adding output data
.scalib_slope
# Chunk 10
gg_data <- .scalib_slope %>%
getElement("data_outputs") %>%
select(._id_., hare_data_plot) %>%
unnest(hare_data_plot)
fig_cal_slope <- ggplot(gg_data) +
aes(x = predicted, y = observed) +
geom_line() +
geom_abline(col = 'grey', linetype = 2, intercept = 0, slope = 1) +
scale_x_continuous(limits = c(0,1),
expand = c(0,0),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%")) +
scale_y_continuous(limits = c(-0, 1),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%"))
fig_cal_slope
# Chunk 11
data_segment <- predrisk_bin_segments(.scalib_slope,
bin_count = 100,
bin_yintercept = 0,
bin_length = 1)
head(data_segment)
# Chunk 12
fig_cal_slope_hist <- fig_cal_slope +
geom_segment(data = data_segment,
inherit.aes = FALSE,
size = 1.2,
color = 'grey',
mapping = aes(x = x,
y = y,
xend = xend,
yend = yend))
fig_cal_slope_hist
# Chunk 13
.scalib_smry <- .scalib_slope %>%
getElement("data_outputs") %>%
select(hare_ici, hare_e50, hare_e90, hare_emax)
# Chunk 14
rspec <- round_spec() %>%
round_half_even() %>%
round_using_decimal(digits = 3)
annotate_label <- table_glue(
'Integrated calibration index: {.scalib_smry$hare_ici}
E50: {.scalib_smry$hare_e50}
E90: {.scalib_smry$hare_e90}
Emax: {.scalib_smry$hare_emax}',
rspec = rspec
)
fig_cal_slope_hist_annotate <-
fig_cal_slope_hist +
annotate(
geom = 'text',
x = 0.05,
y = 0.80,
hjust = 0,
label = annotate_label
)
fig_cal_slope_hist_annotate
.scalib_test <- scalib_gnd(scalib_object = .scalib,
group_count_init = 7)
devtools::load_all(".")
devtools::load_all(".")
.scalib_test <- scalib_gnd(scalib_object = .scalib,
group_count_init = 7)
.scalib_test
# Chunk 1
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# Chunk 2: setup
library(survival.calib)
library(survival)
library(riskRegression)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
theme_set(theme_bw() + theme(panel.grid = element_blank()))
knitr::opts_chunk$set(fig.width=7, fig.height=5)
# Chunk 3
# drop rows with missing values for simplicity
data_init <- na.omit(flchain)
# Chunk 4
# sometimes chapter makes split-sample tests tricky
data_init$chapter <- NULL
# Chunk 5
head(data_init)
# Chunk 6
set.seed(7302016)
mccv_count <- 10
results <- vector(mode = 'list', length = mccv_count)
n_obs_total <- nrow(data_init)
n_obs_train <- round(n_obs_total * 1/2)
pred_horizon <- 1500
for(i in seq(mccv_count)){
train_index <- sample(n_obs_total, size = n_obs_train)
data_train <- data_init[train_index, ]
data_test <- data_init[-train_index, ]
model <- coxph(Surv(futime, death) ~ age + sex + sample.yr + flc.grp,
data = data_train,
x = TRUE)
predrisk <- predictRisk(model, newdata = data_test, times = pred_horizon)
results[[i]] <- predrisk %>%
scalib(pred_horizon = pred_horizon,
event_status = data_test$death,
event_time = data_test$futime) %>%
scalib_hare() %>%
scalib_gnd() %>%
as.data.table()
}
results <- rbindlist(results, idcol = '._iter_.')
results
# Chunk 7
data_outputs <- results  %>%
select(._iter_., ._id_., outputs) %>%
unnest(outputs)
# Chunk 8
data_gnd <- data_outputs %>%
select(starts_with("._"), starts_with("gnd")) %>%
unnest(gnd_data)
data_gnd_pooled <- data_gnd %>%
summarise(gnd_df = sum(gnd_df),
gnd_chisq = sum(gnd_chisq)) %>%
mutate(gnd_pvalue = 1 - pchisq(gnd_chisq, gnd_df))
data_segment <- results %>%
select(._id_., inputs) %>%
unnest(inputs) %>%
pull(pred_risk) %>%
predrisk_bin_segments(bin_count = 75,
bin_length = 2)
data_calslope <- data_outputs %>%
select(._iter_., ._id_., hare_data_plot) %>%
unnest(hare_data_plot)
ggplot(data_calslope) +
aes(x = predicted, y = observed, group = ._iter_.) +
geom_line(col = 'grey', alpha = 2/3) +
geom_smooth(col = 'blue',
group = 1,
method = 'gam',
formula = y ~ s(x, bs = "cs")) +
geom_abline(col = 'black', linetype = 2, intercept = 0, slope = 1) +
scale_x_continuous(limits = c(0, 1),
expand = c(0, 0),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%")) +
scale_y_continuous(limits = c(0, 1),
breaks = seq(0, 1, by = 0.2),
labels = paste0(seq(0, 100, by = 20),"%")) +
labs(color = 'Event status\nat t = 1,000') +
geom_segment(data = data_segment,
inherit.aes = FALSE,
size = 2,
color = 'grey',
mapping = aes(x = x,
y = y,
xend = xend,
yend = yend))
